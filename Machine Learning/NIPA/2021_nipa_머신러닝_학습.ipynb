{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021 nipa 머신러닝 학습.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSp7Zc1bidrItyVI4fCHAi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eunjung-Cho/python_study/blob/master/Machine%20Learning/NIPA/2021_nipa_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2021 NIPA ELICE 머신러닝 학습"
      ],
      "metadata": {
        "id": "NOW4NcxI3lkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 명목형 자료 변환 - 수치매핑"
      ],
      "metadata": {
        "id": "FmH18d-43359"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from elice_utils import EliceUtils\n",
        "\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "# 데이터를 읽어옵니다.\n",
        "titanic = pd.read_csv('./data/titanic.csv')\n",
        "print('변환 전: \\n',titanic['Sex'].head())\n",
        "\n",
        "\"\"\"\n",
        "1. replace를 사용하여 male -> 0, female -> 1로 변환합니다.\n",
        "\"\"\"\n",
        "titanic = titanic.replace({'male':0, 'female':1})\n",
        "\n",
        "# 변환한 성별 데이터를 출력합니다.\n",
        "print('\\n변환 후: \\n',titanic['Sex'].head())"
      ],
      "metadata": {
        "id": "MVK3uvPp38lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 명목형 자료 변환 - 더미방식"
      ],
      "metadata": {
        "id": "M9Eg1Oef4B8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from elice_utils import EliceUtils\n",
        "\n",
        "elice_utils = EliceUtils()\n",
        "   \n",
        "# 데이터를 읽어옵니다.\n",
        "titanic = pd.read_csv('./data/titanic.csv')\n",
        "print('변환 전: \\n',titanic['Embarked'].head())\n",
        "\n",
        "\"\"\"\n",
        "1. get_dummies를 사용하여 변환합니다.\n",
        "\"\"\"\n",
        "dummies = pd.get_dummies(titanic[['Embarked']])\n",
        "\n",
        "# 변환한 Embarked 데이터를 출력합니다.\n",
        "print('\\n변환 후: \\n',dummies.head())"
      ],
      "metadata": {
        "id": "ukir0jwh4Smj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 수치형 자료 변환하기 - 정규화"
      ],
      "metadata": {
        "id": "VKnXHzXN4yke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from elice_utils import EliceUtils\n",
        "\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\"\"\"\n",
        "1. 정규화를 수행하는 함수를 구현합니다.\n",
        "\"\"\"\n",
        "def normal(data):\n",
        "    \n",
        "    data = (data-data.min())/(data.max()-data.min())\n",
        "    \n",
        "    return data\n",
        "\n",
        "# 데이터를 읽어옵니다.\n",
        "titanic = pd.read_csv('./data/titanic.csv')\n",
        "print('변환 전: \\n',titanic['Fare'].head())\n",
        "\n",
        "# normal 함수를 사용하여 정규화합니다.\n",
        "Fare = normal(titanic['Fare'])\n",
        "\n",
        "# 변환한 Fare 데이터를 출력합니다.\n",
        "print('\\n변환 후: \\n',Fare.head())\n"
      ],
      "metadata": {
        "id": "o_LzoPNU4yyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 수치형 자료 변환하기 - 표준화"
      ],
      "metadata": {
        "id": "-4AFFcj06OTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from elice_utils import EliceUtils\n",
        "\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\"\"\"\n",
        "1. 표준화를 수행하는 함수를 구현합니다.\n",
        "\"\"\"\n",
        "def standard(data):\n",
        "    \n",
        "    data = (data-data.mean())/data.std()\n",
        "    \n",
        "    return data\n",
        "    \n",
        "# 데이터를 읽어옵니다.\n",
        "titanic = pd.read_csv('./data/titanic.csv')\n",
        "print('변환 전: \\n',titanic['Fare'].head())\n",
        "\n",
        "# standard 함수를 사용하여 표준화합니다.\n",
        "Fare = standard(titanic['Fare'])\n",
        "\n",
        "# 변환한 Fare 데이터를 출력합니다.\n",
        "print('\\n변환 후: \\n',Fare.head())\n",
        "    "
      ],
      "metadata": {
        "id": "2rGolk6o6Nwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 결측값 처리하기"
      ],
      "metadata": {
        "id": "LTPyy8mg6UXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from elice_utils import EliceUtils\n",
        "\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "    \n",
        "# 데이터를 읽어옵니다.\n",
        "titanic = pd.read_csv('./data/titanic.csv')\n",
        "# 변수 별 데이터 수를 확인하여 결측 값이 어디에 많은지 확인합니다.\n",
        "print(titanic.info(),'\\n')\n",
        "\n",
        "\"\"\"\n",
        "1. Cabin 변수를 제거합니다.\n",
        "\"\"\"\n",
        "titanic_1 = titanic.drop(columns=['Cabin'])\n",
        "# Cabin 변수를 제거 후 결측값이 어디에 남아 있는지 확인합니다.\n",
        "print('Cabin 변수 제거')\n",
        "print(titanic_1.info(),'\\n')\n",
        "\n",
        "\"\"\"\n",
        "2. 결측값이 존재하는 샘플 제거합니다.\n",
        "\"\"\"\n",
        "titanic_2 = titanic_1.dropna()\n",
        "# 결측값이 존재하는지 확인합니다.\n",
        "print('결측값이 존재하는 샘플 제거')\n",
        "print(titanic_2.info())\n"
      ],
      "metadata": {
        "id": "nZXiflq66W1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이상치 처리하기"
      ],
      "metadata": {
        "id": "sBqvC7ft7aqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from elice_utils import EliceUtils\n",
        "\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "\n",
        "# 데이터를 읽어옵니다.\n",
        "titanic = pd.read_csv('./data/titanic.csv')\n",
        "\n",
        "# Cabin 변수를 제거합니다.\n",
        "titanic_1 = titanic.drop(columns=['Cabin'])\n",
        "\n",
        "# 결측값이 존재하는 샘플 제거합니다.\n",
        "titanic_2 = titanic_1.dropna()\n",
        "\n",
        "# (Age 값 - 내림 Age 값) 0 보다 크다면 소수점을 갖는 데이터로 분류합니다.\n",
        "outlier = titanic_2[titanic_2['Age']-np.floor(titanic_2['Age']) > 0 ]['Age']\n",
        "\n",
        "print('소수점을 갖는 Age 변수 이상치')\n",
        "print(outlier)\n",
        "print('이상치 처리 전 샘플 개수: %d' %(len(titanic_2)))\n",
        "print('이상치 개수: %d' %(len(outlier)))\n",
        "\n",
        "\"\"\"\n",
        "1. 이상치를 처리합니다.\n",
        "\"\"\"\n",
        "titanic_3 = titanic_2[titanic_2['Age']-np.floor(titanic_2['Age']) == 0 ]\n",
        "print('이상치 처리 후 샘플 개수: %d' %(len(titanic_3)))\n"
      ],
      "metadata": {
        "id": "3TR7er177b4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 분리하기"
      ],
      "metadata": {
        "id": "KlLmcmRZ7riE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1\n",
        "import pandas as pd\n",
        "2\n",
        "import numpy as np\n",
        "3\n",
        "from sklearn.model_selection import train_test_split\n",
        "4\n",
        "from elice_utils import EliceUtils\n",
        "5\n",
        "​\n",
        "6\n",
        "elice_utils = EliceUtils()\n",
        "7\n",
        "​\n",
        "8\n",
        "# 데이터를 읽어옵니다.\n",
        "9\n",
        "titanic = pd.read_csv('./data/titanic.csv')\n",
        "10\n",
        "​\n",
        "11\n",
        "# Cabin 변수를 제거합니다.\n",
        "12\n",
        "titanic_1 = titanic.drop(columns=['Cabin'])\n",
        "13\n",
        "​\n",
        "14\n",
        "# 결측값이 존재하는 샘플 제거합니다.\n",
        "15\n",
        "titanic_2 = titanic_1.dropna()\n",
        "16\n",
        "​\n",
        "17\n",
        "# 이상치를 처리합니다.\n",
        "18\n",
        "titanic_3 = titanic_2[titanic_2['Age']-np.floor(titanic_2['Age']) == 0 ]\n",
        "19\n",
        "print('전체 샘플 데이터 개수: %d' %(len(titanic_3)))\n",
        "20\n",
        "​\n",
        "21\n",
        "\"\"\"\n",
        "22\n",
        "1. feature 데이터와 label 데이터를 분리합니다.\n",
        "23\n",
        "\"\"\"\n",
        "24\n",
        "X = titanic_3.drop(columns=['Survived'])\n",
        "25\n",
        "y = titanic_3['Survived']\n",
        "26\n",
        "print('X 데이터 개수: %d' %(len(X)))\n",
        "27\n",
        "print('y 데이터 개수: %d' %(len(y)))\n",
        "28\n",
        "​\n",
        "29\n",
        "\"\"\"\n",
        "30\n",
        "2. 학습용, 평가용 데이터로 분리합니다.\n",
        "31\n",
        "\"\"\"\n",
        "32\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "33\n",
        "​\n",
        "34\n",
        "# 분리한 데이터의 개수를 출력합니다.\n",
        "35\n",
        "print('학습용 데이터 개수: %d' %(len(X_train)))\n",
        "36\n",
        "print('평가용 데이터 개수: %d' %(len(X_test)))\n",
        "37\n",
        "​\n",
        "\n"
      ],
      "metadata": {
        "id": "FEMIE4ki7svA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 회귀"
      ],
      "metadata": {
        "id": "014nTQ__88QT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 단순선형회귀 - 데이터 전처리"
      ],
      "metadata": {
        "id": "UZk_W5qC89SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "mpl.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import elice_utils\n",
        "eu = elice_utils.EliceUtils()\n",
        "\n",
        "    \n",
        "X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]\n",
        "Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]\n",
        "\n",
        "\"\"\"\n",
        "1. X의 형태를 변환하여 train_X에 저장합니다.\n",
        "\"\"\"\n",
        "train_X = pd.DataFrame(X, columns=['X'])\n",
        "\n",
        "\"\"\"\n",
        "2. Y의 형태를 변환하여 train_Y에 저장합니다.\n",
        "\"\"\"\n",
        "train_Y = pd.Series(Y)\n",
        "\n",
        "# 변환된 데이터를 출력합니다.\n",
        "print('전 처리한 X 데이터: \\n {}'.format(train_X))\n",
        "print('전 처리한 X 데이터 shape: {}\\n'.format(train_X.shape))\n",
        "\n",
        "print('전 처리한 Y 데이터: \\n {}'.format(train_Y))\n",
        "print('전 처리한 Y 데이터 shape: {}'.format(train_Y.shape))"
      ],
      "metadata": {
        "id": "yjytPt3F8_7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 단순선형회귀 - 학습하기"
      ],
      "metadata": {
        "id": "APoaFI4u9YyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "mpl.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import elice_utils\n",
        "eu = elice_utils.EliceUtils()\n",
        "\n",
        "\n",
        "X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]\n",
        "Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]\n",
        "\n",
        "train_X = pd.DataFrame(X, columns=['X'])\n",
        "train_Y = pd.Series(Y)\n",
        "\n",
        "\"\"\"\n",
        "1. 모델을 초기화 합니다.\n",
        "\"\"\"\n",
        "lrmodel = LinearRegression()\n",
        "\n",
        "\"\"\"\n",
        "2. train_X, train_Y 데이터를 학습합니다.\n",
        "\"\"\"\n",
        "lrmodel.fit(train_X, train_Y)\n",
        "\n",
        "\n",
        "# 학습한 결과를 시각화하는 코드입니다.\n",
        "plt.scatter(X, Y) \n",
        "plt.plot([0, 10], [lrmodel.intercept_, 10 * lrmodel.coef_[0] + lrmodel.intercept_], c='r') \n",
        "plt.xlim(0, 10) \n",
        "plt.ylim(0, 10) \n",
        "plt.title('Training Result')\n",
        "plt.savefig(\"test.png\") \n",
        "eu.send_image(\"test.png\")"
      ],
      "metadata": {
        "id": "6W6KZH5J9JyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 단순선형회귀 - 예측하기"
      ],
      "metadata": {
        "id": "k7VVFznQ9a0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "mpl.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import elice_utils\n",
        "eu = elice_utils.EliceUtils()\n",
        "\n",
        "\n",
        "    \n",
        "X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]\n",
        "Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]\n",
        "\n",
        "train_X = pd.DataFrame(X, columns=['X'])\n",
        "train_Y = pd.Series(Y)\n",
        "\n",
        "# 모델을 트레이닝합니다.\n",
        "lrmodel = LinearRegression()\n",
        "lrmodel.fit(train_X, train_Y)\n",
        "\n",
        "\"\"\"\n",
        "1. train_X에 대해서 예측합니다.\n",
        "\"\"\"\n",
        "pred_X = lrmodel.predict(train_X)\n",
        "print('train_X에 대한 예측값 : \\n{}\\n'.format(pred_X))\n",
        "print('실제값 : \\n{}'.format(train_Y))\n"
      ],
      "metadata": {
        "id": "bO4Fm0IY9VWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 다중선형회귀 - 데이터 전처리"
      ],
      "metadata": {
        "id": "BEKGDVuG9iBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"data/Advertising.csv\")\n",
        "\n",
        "print('원본 데이터 샘플 :')\n",
        "print(df.head(),'\\n')\n",
        "\n",
        "# 입력 변수로 사용하지 않는 Unnamed: 0 변수 데이터를 삭제합니다\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "\"\"\"\n",
        "1. Sales 변수는 label 데이터로 Y에 저장하고 나머진 X에 저장합니다.\n",
        "\"\"\"\n",
        "X = df.drop(columns=['Sales'])\n",
        "Y = df['Sales']\n",
        "\n",
        "\"\"\"\n",
        "2. 학습용 평가용 데이터로 분리합니다.\n",
        "\"\"\"\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 전 처리한 데이터를 출력합니다\n",
        "print('train_X : ')\n",
        "print(train_X.head(),'\\n')\n",
        "print('train_Y : ')\n",
        "print(train_Y.head(),'\\n')\n",
        "\n",
        "print('test_X : ')\n",
        "print(test_X.head(),'\\n')\n",
        "print('test_Y : ')\n",
        "print(test_Y.head())\n"
      ],
      "metadata": {
        "id": "WQsxXtqX9mzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 다중선형회귀 - 학습하기"
      ],
      "metadata": {
        "id": "W8NhIpZH9jgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터를 읽고 전 처리합니다\n",
        "df = pd.read_csv(\"data/Advertising.csv\")\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "X = df.drop(columns=['Sales'])\n",
        "Y = df['Sales']\n",
        "\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "1.  다중 선형 회귀 모델을 초기화 하고 학습합니다\n",
        "\"\"\"\n",
        "lrmodel = LinearRegression()\n",
        "lrmodel.fit(train_X, train_Y)\n",
        "\n",
        "\"\"\"\n",
        "2. 학습된 파라미터 값을 불러옵니다\n",
        "\"\"\"\n",
        "beta_0 = lrmodel.intercept_ # y절편 (기본 판매량)\n",
        "beta_1 = lrmodel.coef_[0] # 1번째 변수에 대한 계수 (페이스북)\n",
        "beta_2 = lrmodel.coef_[1] # 2번째 변수에 대한 계수 (TV)\n",
        "beta_3 = lrmodel.coef_[2] # 3번째 변수에 대한 계수 (신문)\n",
        "\n",
        "print(\"beta_0: %f\" % beta_0)\n",
        "print(\"beta_1: %f\" % beta_1)\n",
        "print(\"beta_2: %f\" % beta_2)\n",
        "print(\"beta_3: %f\" % beta_3)"
      ],
      "metadata": {
        "id": "osqIMBBz-IpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 다중선형회귀 - 예측하기"
      ],
      "metadata": {
        "id": "ALbcKW7l9jzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터를 읽고 전 처리합니다\n",
        "df = pd.read_csv(\"data/Advertising.csv\")\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "X = df.drop(columns=['Sales'])\n",
        "Y = df['Sales']\n",
        "\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# 다중 선형 회귀 모델을 초기화 하고 학습합니다\n",
        "lrmodel = LinearRegression()\n",
        "lrmodel.fit(train_X, train_Y)\n",
        "\n",
        "\n",
        "print('test_X : ')\n",
        "print(test_X)\n",
        "\n",
        "\"\"\"\n",
        "1. test_X에 대해서 예측합니다.\n",
        "\"\"\"\n",
        "pred_X = lrmodel.predict(test_X)\n",
        "print('test_X에 대한 예측값 : \\n{}\\n'.format(pred_X))\n",
        "\n",
        "# 새로운 데이터 df1을 정의합니다\n",
        "df1 = pd.DataFrame(np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]]), columns=['FB', 'TV', 'Newspaper'])\n",
        "print('df1 : ')\n",
        "print(df1)\n",
        "\n",
        "\"\"\"\n",
        "2. df1에 대해서 예측합니다.\n",
        "\"\"\"\n",
        "pred_df1 = lrmodel.predict(df1)\n",
        "print('df1에 대한 예측값 : \\n{}'.format(pred_df1))"
      ],
      "metadata": {
        "id": "7gW338qr-aM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 회귀알고리즘 평가지표- MSE, MAE\n",
        "\n",
        "Sales 예측 모델의 성능을 평가하기 위해서 다양한 회귀 알고리즘 평가 지표를 사용하여 비교해보겠습니다.\n",
        "\n",
        "이번 실습에서는 학습용 및 평가용 데이터에 대해서 MSE와 MAE을 계산해보겠습니다.\n",
        "\n",
        "MSE와 MAE는 아래와 같이 정의할 수 있고 sklearn 라이브러리 함수를 통하여 쉽게 구할 수 있습니다.\n",
        "\n",
        "MSE=1NΣiN(실제값i−예측값i)2MSE = \\frac{1}{N}\\Sigma_{i}^{N} (실제값_{i} - 예측값_{i})^{2}MSE= \n",
        "N\n",
        "1\n",
        "​\n",
        " Σ \n",
        "i\n",
        "N\n",
        "​\n",
        " (실제값 \n",
        "i\n",
        "​\n",
        " −예측값 \n",
        "i\n",
        "​\n",
        " ) \n",
        "2\n",
        " \n",
        "\n",
        "MAE=1NΣiN∣실제값i−예측값i∣MAE = \\frac{1}{N}\\Sigma_{i}^{N} |실제값_{i} - 예측값_{i}|MAE= \n",
        "N\n",
        "1\n",
        "​\n",
        " Σ \n",
        "i\n",
        "N\n",
        "​\n",
        " ∣실제값 \n",
        "i\n",
        "​\n",
        " −예측값 \n",
        "i\n",
        "​\n",
        " ∣\n",
        "\n",
        "NNN은 전체 샘플의 개수를 의미합니다.\n",
        "\n",
        "MSE, MAE 평가 지표를 계산하기 위한 사이킷런 함수/라이브러리\n",
        "\n",
        "mean_squared_error(y_true, y_pred): MSE 값 계산하기\n",
        "\n",
        "mean_absolute_error(y_true, y_pred): MAE 값 계산하기"
      ],
      "metadata": {
        "id": "wb0IareJ-dz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# 데이터를 읽고 전 처리합니다\n",
        "df = pd.read_csv(\"data/Advertising.csv\")\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "X = df.drop(columns=['Sales'])\n",
        "Y = df['Sales']\n",
        "\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# 다중 선형 회귀 모델을 초기화 하고 학습합니다\n",
        "lrmodel = LinearRegression()\n",
        "lrmodel.fit(train_X, train_Y)\n",
        "\n",
        "\n",
        "# train_X 의 예측값을 계산합니다\n",
        "pred_train = lrmodel.predict(train_X)\n",
        "\n",
        "\"\"\"\n",
        "1. train_X 의 MSE, MAE 값을 계산합니다\n",
        "\"\"\"\n",
        "MSE_train = mean_squared_error(train_Y, pred_train)\n",
        "MAE_train = mean_absolute_error(train_Y, pred_train)\n",
        "print('MSE_train : %f' % MSE_train)\n",
        "print('MAE_train : %f' % MAE_train)\n",
        "\n",
        "# test_X 의 예측값을 계산합니다\n",
        "pred_test = lrmodel.predict(test_X)\n",
        "\n",
        "\"\"\"\n",
        "2. test_X 의 MSE, MAE 값을 계산합니다\n",
        "\"\"\"\n",
        "MSE_test = mean_squared_error(test_Y, pred_test)\n",
        "MAE_test = mean_absolute_error(test_Y, pred_test)\n",
        "print('MSE_test : %f' % MSE_test)\n",
        "print('MAE_test : %f' % MAE_test)\n"
      ],
      "metadata": {
        "id": "bIRT0Bqx-kM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 회귀 알고리즘 평가 지표 - R2\n",
        "\n",
        "R2 score 는 아래와 같이 정의할 수 있고 sklearn 라이브러리 함수를 통하여 쉽게 구할 수 있습니다.\n",
        "\n",
        "R2=1−RSSTSSR^{2} = 1-\\frac{RSS}{TSS}R \n",
        "2\n",
        " =1− \n",
        "TSS\n",
        "RSS\n",
        "​\n",
        " \n",
        "\n",
        "TSS=ΣiN(실제값i−평균실제값)2TSS=\\Sigma_{i}^{N}(실제값_{i}-평균실제값)^{2}TSS=Σ \n",
        "i\n",
        "N\n",
        "​\n",
        " (실제값 \n",
        "i\n",
        "​\n",
        " −평균실제값) \n",
        "2\n",
        " \n",
        "\n",
        "NNN은 전체 샘플의 개수를 의미합니다.\n",
        "\n",
        "R2 평가 지표를 계산하기 위한 사이킷런 함수/라이브러리\n",
        "\n",
        "r2_score(y_true, y_pred): R2 score 값 계산하기"
      ],
      "metadata": {
        "id": "M_o3QvM-_Zzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1\n",
        "import numpy as np\n",
        "2\n",
        "import pandas as pd\n",
        "3\n",
        "from sklearn.linear_model import LinearRegression\n",
        "4\n",
        "from sklearn.metrics import r2_score\n",
        "5\n",
        "from sklearn.model_selection import train_test_split\n",
        "6\n",
        "​\n",
        "7\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "8\n",
        "from sklearn.metrics import mean_squared_error\n",
        "9\n",
        "​\n",
        "10\n",
        "​\n",
        "11\n",
        "# 데이터를 읽고 전 처리합니다\n",
        "12\n",
        "df = pd.read_csv(\"data/Advertising.csv\")\n",
        "13\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "14\n",
        "​\n",
        "15\n",
        "X = df.drop(columns=['Sales'])\n",
        "16\n",
        "Y = df['Sales']\n",
        "17\n",
        "​\n",
        "18\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "19\n",
        "​\n",
        "20\n",
        "​\n",
        "21\n",
        "# 다중 선형 회귀 모델을 초기화 하고 학습합니다\n",
        "22\n",
        "lrmodel = LinearRegression()\n",
        "23\n",
        "lrmodel.fit(train_X, train_Y)\n",
        "24\n",
        "​\n",
        "25\n",
        "​\n",
        "26\n",
        "# train_X 의 예측값을 계산합니다\n",
        "27\n",
        "pred_train = lrmodel.predict(train_X)\n",
        "28\n",
        "​\n",
        "29\n",
        "\"\"\"\n",
        "30\n",
        "1. train_X 의 R2 값을 계산합니다\n",
        "31\n",
        "\"\"\"\n",
        "32\n",
        "R2_train = r2_score(train_Y, pred_train)\n",
        "33\n",
        "print('R2_train : %f' % R2_train)\n",
        "34\n",
        "​\n",
        "35\n",
        "# test_X 의 예측값을 계산합니다\n",
        "36\n",
        "pred_test = lrmodel.predict(test_X)\n",
        "37\n",
        "​\n",
        "38\n",
        "\"\"\"\n",
        "39\n",
        "2. test_X 의 R2 값을 계산합니다\n",
        "40\n",
        "\"\"\"\n",
        "41\n",
        "R2_test = r2_score(test_Y, pred_test)\n",
        "42\n",
        "print('R2_test : %f' % R2_test)\n",
        "43\n",
        "​\n",
        "\n"
      ],
      "metadata": {
        "id": "6NIQfCT8_XZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 분류"
      ],
      "metadata": {
        "id": "ipuH6jFl_goq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 간단한 의사결정나무"
      ],
      "metadata": {
        "id": "BVDH9uk3FmWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 풍속을 threshold 값에 따라 분리하는 의사결정나무 모델 함수\n",
        "def binary_tree(data, threshold):\n",
        "    \n",
        "    yes = []\n",
        "    no = []\n",
        "    \n",
        "    # data로부터 풍속 값마다 비교를 하기 위한 반복문\n",
        "    for wind in data['풍속']:\n",
        "    \n",
        "        # threshold 값과 비교하여 분리합니다.\n",
        "        if wind > threshold:\n",
        "            yes.append(wind)\n",
        "        else:\n",
        "            no.append(wind)\n",
        "    \n",
        "    # 예측한 결과를 DataFrame 형태로 저장합니다.\n",
        "    data_yes = pd.DataFrame({'풍속': yes, '예상 지연 여부': ['Yes']*len(yes)})\n",
        "    data_no = pd.DataFrame({'풍속': no, '예상 지연 여부': ['No']*len(no)})\n",
        "    \n",
        "    return data_no.append(data_yes,ignore_index=True)\n",
        "\n",
        "# 풍속에 따른 항공 지연 여부 데이터\n",
        "Wind = [1, 1.5, 2.5, 5, 5.5, 6.5]\n",
        "Delay  = ['No', 'No', 'No', 'Yes', 'Yes', 'Yes']\n",
        "\n",
        "# 위 데이터를 DataFrame 형태로 저장합니다.\n",
        "data = pd.DataFrame({'풍속': Wind, '지연 여부': Delay})\n",
        "print(data,'\\n')\n",
        "\n",
        "\"\"\"\n",
        "1. binary_tree 모델을 사용하여 항공 지연 여부를 예측합니다.\n",
        "\"\"\"\n",
        "data_pred = binary_tree(data, threshold = 3)\n",
        "print(data_pred,'\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "mz4i__IlFhMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### sklearn을 사용한 의사결정나무 - 데이터 전 처리"
      ],
      "metadata": {
        "id": "t4sfPz5XFpJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from elice_utils import EliceUtils\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "# sklearn에 저장된 데이터를 불러 옵니다.\n",
        "X, Y = load_iris(return_X_y = True)\n",
        "\n",
        "# DataFrame으로 변환\n",
        "df = pd.DataFrame(X, columns=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'])\n",
        "df['클래스'] = Y\n",
        "\n",
        "X = df.drop(columns=['클래스'])\n",
        "Y = df['클래스']\n",
        "\n",
        "\"\"\"\n",
        "1. 학습용 평가용 데이터로 분리합니다\n",
        "\"\"\"\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "# 원본 데이터 출력\n",
        "print('원본 데이터 : \\n',df.head(),'\\n')\n",
        "\n",
        "# 전 처리한 데이터 5개만 출력합니다\n",
        "print('train_X : ')\n",
        "print(train_X[:5],'\\n')\n",
        "print('train_Y : ')\n",
        "print(train_Y[:5],'\\n')\n",
        "\n",
        "print('test_X : ')\n",
        "print(test_X[:5],'\\n')\n",
        "print('test_Y : ')\n",
        "print(test_Y[:5])"
      ],
      "metadata": {
        "id": "70Ugwr7tH4OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### sklearn을 사용한 의사결정나무 - 학습하기"
      ],
      "metadata": {
        "id": "XtXJ2LtjJ_hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "\n",
        "from elice_utils import EliceUtils\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "# sklearn에 저장된 데이터를 불러 옵니다.\n",
        "X, Y = load_iris(return_X_y = True)\n",
        "\n",
        "# DataFrame으로 변환\n",
        "df = pd.DataFrame(X, columns=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'])\n",
        "df['클래스'] = Y\n",
        "\n",
        "X = df.drop(columns=['클래스'])\n",
        "Y = df['클래스']\n",
        "    \n",
        "# 학습용 평가용 데이터로 분리합니다\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "# DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다\n",
        "DTmodel = DecisionTreeClassifier()\n",
        "DTmodel.fit(train_X, train_Y)\n",
        "\n",
        "\n",
        "# 학습한 결과를 출력합니다\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "fig = plt.figure(figsize=(25,20))\n",
        "_ = tree.plot_tree(DTmodel, \n",
        "                   feature_names=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'],  \n",
        "                   class_names=['setosa', 'versicolor', 'virginica'],\n",
        "                   filled=True)\n",
        "\n",
        "fig.savefig(\"decision_tree.png\")\n",
        "elice_utils.send_image(\"decision_tree.png\")\n"
      ],
      "metadata": {
        "id": "59BxfdVPJ-TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### sklearn을 사용한 의사결정나무 - 예측하기"
      ],
      "metadata": {
        "id": "SGPqbvEVKG9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "\n",
        "from elice_utils import EliceUtils\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "# sklearn에 저장된 데이터를 불러 옵니다.\n",
        "X, Y = load_iris(return_X_y = True)\n",
        "\n",
        "# DataFrame으로 변환\n",
        "df = pd.DataFrame(X, columns=['꽃받침 길이','꽃받침 넓이', '꽃잎 길이', '꽃잎 넓이'])\n",
        "df['클래스'] = Y\n",
        "\n",
        "X = df.drop(columns=['클래스'])\n",
        "Y = df['클래스']\n",
        "    \n",
        "# 학습용 평가용 데이터로 분리합니다\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "# DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다\n",
        "DTmodel = DecisionTreeClassifier()\n",
        "DTmodel.fit(train_X, train_Y)\n",
        "\n",
        "\n",
        "# test_X에 대해서 예측합니다.\n",
        "pred_X = DTmodel.predict(test_X)\n",
        "print('test_X에 대한 예측값 : \\n{}'.format(pred_X))"
      ],
      "metadata": {
        "id": "5VpVDwF7KGyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### confusion Matrix - 혼동행렬\n",
        "\n",
        "\n",
        "혼동 행렬(Confusion matrix)은 분류 문제에서 모델을 학습시킨 뒤, 모델에서 데이터의 X값을 집어넣어 얻은 예상되는 y값과, 실제 데이터의 y값을 비교하여 정확히 분류 되었는지 확인하는 메트릭(metric)이라고 할 수 있습니다.\n",
        "\n",
        "image\n",
        "\n",
        "위 표가 바로 혼동 행렬이며, 각 표에 속한 값은 다음을 의미합니다.\n",
        "\n",
        "True Positive (TP) : 실제 값은 Positive, 예측된 값도 Positive.\n",
        "False Positive (FP) : 실제 값은 Negative, 예측된 값은 Positive.\n",
        "False Negative (FN) : 실제 값은 Positive, 예측된 값은 Negative.\n",
        "True Negative (TN) : 실제 값은 Negative, 예측된 값도 Negative.\n",
        "sklearn 안에는 위 4개 평가 값을 얻기 위해 사용할 수 있는 기능이 정의되어 있습니다.\n",
        "\n",
        "이번 실습에서는 2개의 클래스를 가진 분류 데이터를 이용하여 혼동 행렬을 직접 출력해보고,확인해보도록 하겠습니다."
      ],
      "metadata": {
        "id": "svbE2YpdKK1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "from elice_utils import EliceUtils\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "# sklearn에 저장된 데이터를 불러 옵니다.\n",
        "X, Y = load_breast_cancer(return_X_y = True)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# 데이터 정보를 출력합니다\n",
        "print('전체 샘플 개수: ',len(X))\n",
        "print('X의 feature 개수: ',len(X[0]))\n",
        "\n",
        "# 학습용 평가용 데이터로 분리합니다\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "# 분리된 평가용 데이터 정보를 출력합니다\n",
        "print('평가용 샘플 개수: ',len(test_Y))\n",
        "print('클래스 0인 평가용 샘플 개수: ',len(test_Y)-sum(test_Y))\n",
        "print('클래스 1인 평가용 샘플 개수: ',sum(test_Y),'\\n')\n",
        "\n",
        "# DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다\n",
        "DTmodel = DecisionTreeClassifier()\n",
        "DTmodel.fit(train_X, train_Y)\n",
        "\n",
        "# test_X을 바탕으로 예측한 값을 저장합니다\n",
        "y_pred = DTmodel.predict(test_X)\n",
        "\n",
        "\"\"\"\n",
        "1. 혼동 행렬을 계산합니다\n",
        "\"\"\"\n",
        "cm = confusion_matrix(test_Y, y_pred)\n",
        "print('Confusion Matrix : \\n {}'.format(cm))\n",
        "\n",
        "# 혼동 행렬을 출력합니다\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "ax = sns.heatmap(cm, annot=True)\n",
        "ax.set(title='Confusion Matrix',\n",
        "            ylabel='True label',\n",
        "            xlabel='Predicted label')\n",
        "fig.savefig(\"decistion_tree.png\")\n",
        "elice_utils.send_image(\"decistion_tree.png\")"
      ],
      "metadata": {
        "id": "ERzkQ5i7KXnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 정확도(Accuracy) 계산하기정확도 계산을 위한 사이킷런 함수/라이브러리\n",
        "\n",
        "DTmodel.score(train_X, train_Y)\n",
        ": train_X 데이터에 대한 정확도(accuracy) 값을 계산합니다.\n",
        "데이터 정보\n",
        "\n",
        "load_breast_cancer 유방암 유무 판별 데이터를 불러오는 함수\n",
        "\n",
        "X(Feature 데이터) : 30개의 환자 데이터\n",
        "Y(Label 데이터) : 0 음성(악성), 1 양성(정상)"
      ],
      "metadata": {
        "id": "6_hny5uUKepz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "from elice_utils import EliceUtils\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "# sklearn에 저장된 데이터를 불러 옵니다.\n",
        "X, Y = load_breast_cancer(return_X_y = True)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# 학습용 평가용 데이터로 분리합니다\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "# 분리된 데이터 정보를 출력합니다\n",
        "print('학습용 샘플 개수: ',len(train_Y))\n",
        "print('클래스 0인 학습용 샘플 개수: ',len(train_Y)-sum(train_Y))\n",
        "print('클래스 1인 학습용 샘플 개수: ',sum(train_Y),'\\n')\n",
        "\n",
        "print('평가용 샘플 개수: ',len(test_Y))\n",
        "print('클래스 0인 평가용 샘플 개수: ',len(test_Y)-sum(test_Y))\n",
        "print('클래스 1인 평가용 샘플 개수: ',sum(test_Y),'\\n')\n",
        "\n",
        "# DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다\n",
        "DTmodel = DecisionTreeClassifier()\n",
        "DTmodel.fit(train_X, train_Y)\n",
        "\n",
        "\n",
        "# 예측한 값을 저장합니다\n",
        "y_pred_train = DTmodel.predict(train_X)\n",
        "y_pred_test = DTmodel.predict(test_X)\n",
        "\n",
        "# 혼동 행렬을 계산합니다\n",
        "cm_train = confusion_matrix(train_Y, y_pred_train)\n",
        "cm_test = confusion_matrix(test_Y, y_pred_test)\n",
        "print('train_X Confusion Matrix : \\n {}'.format(cm_train))\n",
        "print('test_X Confusion Matrix : \\n {}'.format(cm_test))\n",
        "\n",
        "\"\"\"\n",
        "1. 정확도를 계산합니다.\n",
        "\"\"\"\n",
        "acc_train = DTmodel.score(train_X, train_Y)\n",
        "acc_test = DTmodel.score(test_X, test_Y)\n",
        "\n",
        "# 정확도를 출력합니다.\n",
        "print('train_X Accuracy: %f' % (acc_train))\n",
        "print('test_X Accuracy: %f' % (acc_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "7hP6Q1OdKfT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 정밀도(Precision), 재현율(Recall) 계산하기\n",
        "\n",
        "정밀도와 재현율 계산을 위한 사이킷런 함수/라이브러리\n",
        "\n",
        "precision_score(train_Y, y_pred_train)\n",
        ": 학습용 데이터에 대한 정밀도(precision) 값을 계산합니다.\n",
        "\n",
        "recall_score(train_Y, y_pred_train)\n",
        ": 학습용 데이터에 대한 재현율(recall) 값을 계산합니다.\n",
        "\n",
        "데이터 정보\n",
        "\n",
        "load_breast_cancer 유방암 유무 판별 데이터를 불러오는 함수\n",
        "\n",
        "X(Feature 데이터) : 30개의 환자 데이터\n",
        "Y(Label 데이터) : 0 음성(악성), 1 양성(정상)"
      ],
      "metadata": {
        "id": "zv6lYvQDMmWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from elice_utils import EliceUtils\n",
        "elice_utils = EliceUtils()\n",
        "\n",
        "\n",
        "# sklearn에 저장된 데이터를 불러 옵니다.\n",
        "X, Y = load_breast_cancer(return_X_y = True)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# 학습용 평가용 데이터로 분리합니다\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "\n",
        "# DTmodel에 의사결정나무 모델을 초기화 하고 학습합니다\n",
        "DTmodel = DecisionTreeClassifier()\n",
        "DTmodel.fit(train_X, train_Y)\n",
        "\n",
        "\n",
        "# 예측한 값을 저장합니다\n",
        "y_pred_train = DTmodel.predict(train_X)\n",
        "y_pred_test = DTmodel.predict(test_X)\n",
        "\n",
        "# 혼동 행렬을 계산합니다\n",
        "cm_train = confusion_matrix(train_Y, y_pred_train)\n",
        "cm_test = confusion_matrix(test_Y, y_pred_test)\n",
        "print('train_X Confusion Matrix : \\n {}'.format(cm_train))\n",
        "print('test_X Confusion Matrix : \\n {}'.format(cm_test),'\\n')\n",
        "\n",
        "\"\"\"\n",
        "1. 정밀도를 계산합니다.\n",
        "\"\"\"\n",
        "precision_train = precision_score(train_Y, y_pred_train)\n",
        "precision_test = precision_score(test_Y, y_pred_test)\n",
        "\n",
        "# 정밀도를 출력합니다.\n",
        "print('train_X Precision: %f' % (precision_train))\n",
        "print('test_X Precision: %f' % (precision_test),'\\n')\n",
        "\n",
        "\"\"\"\n",
        "2. 재현율을 계산합니다.\n",
        "\"\"\"\n",
        "recall_train = recall_score(train_Y, y_pred_train)\n",
        "recall_test = recall_score(test_Y, y_pred_test)\n",
        "\n",
        "# 재현율을 출력합니다.\n",
        "print('train_X Recall: %f' % (recall_train))\n",
        "print('test_X Recall: %f' % (recall_test))"
      ],
      "metadata": {
        "id": "D3yGSuh-MkUA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}